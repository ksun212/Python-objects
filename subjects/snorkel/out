/home/user/thefuck-master/pre_run_biend.py:3884: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6C) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3894: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(O6C) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3918: DeprecationWarning: invalid escape sequence \ 
  f.write('$extenion\ set$ & ' + ' & '.join(EXT_SET) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3919: DeprecationWarning: invalid escape sequence \ 
  f.write('$extenion\ event$ & ' + ' & '.join(EXT_EVENT) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4046: DeprecationWarning: invalid escape sequence \_
  d_ = d.replace('_', '\_')
/home/user/thefuck-master/pre_run_biend.py:4057: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6[:10]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4067: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6[10:]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4079: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6ov[:10]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4091: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6ov[10:]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4213: DeprecationWarning: invalid escape sequence \_
  d_ = d.replace('_', '\_')
/home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dash/testing/plugin.py:92: PytestDeprecationWarning: The hookimpl pytest_addhooks uses old-style configuration options (marks or attributes).
Please use the pytest.hookimpl(tryfirst=True) decorator instead
 to configure the hooks.
 See https://docs.pytest.org/en/latest/deprecations.html#configuring-hook-specs-impls-using-markers
  @pytest.mark.tryfirst
============================= test session starts ==============================
platform linux -- Python 3.9.15+, pytest-7.2.0, pluggy-1.0.0
rootdir: /home/user/snorkel, configfile: setup.cfg
plugins: mock-3.10.0, hypothesis-6.56.4, httpbin-1.0.2, cov-4.0.0, time-machine-2.9.0, html-3.2.0, Faker-15.3.4, anyio-3.6.2, flaky-3.7.0, hydra-core-1.3.2, xdist-3.2.1, test-utils-0.0.8, lazy-fixture-0.6.3, docker-1.0.1, xonsh-0.13.4, pylama-8.4.1, dash-2.9.1
collected 233 items

test/analysis/test_error_analysis.py .....                               [  2%]
test/analysis/test_metrics.py ............                               [  7%]
test/analysis/test_scorer.py ........                                    [ 10%]
test/augmentation/apply/test_tf_applier.py ................              [ 17%]
test/augmentation/policy/test_core.py ..                                 [ 18%]
test/augmentation/policy/test_sampling.py ..                             [ 19%]
test/classification/test_classifier_convergence.py .                     [ 19%]
test/classification/test_data.py ..                                      [ 20%]
test/classification/test_loss.py ......                                  [ 23%]
test/classification/test_multitask_classifier.py ..............          [ 29%]
test/classification/test_task.py .                                       [ 29%]
test/classification/test_utils.py ...                                    [ 30%]
test/classification/training/test_trainer.py ..........                  [ 35%]
test/classification/training/loggers/test_checkpointer.py .......        [ 38%]
test/classification/training/loggers/test_log_manager.py .....           [ 40%]
test/classification/training/loggers/test_log_writer.py ...              [ 41%]
test/classification/training/loggers/test_tensorboard_writer.py .        [ 42%]
test/classification/training/schedulers/test_schedulers.py ..            [ 42%]
test/labeling/test_analysis.py ............                              [ 48%]
test/labeling/test_convergence.py .                                      [ 48%]
test/labeling/test_utils.py .                                            [ 48%]
test/labeling/apply/test_lf_applier.py ..........FFFFFFF.FF              [ 57%]
test/labeling/lf/test_core.py ........                                   [ 60%]
test/labeling/lf/test_nlp.py FFF.FFF                                     [ 63%]
test/labeling/model/test_baseline.py ...                                 [ 65%]
test/labeling/model/test_label_model.py ...........................      [ 76%]
test/labeling/model/test_logger.py ...                                   [ 78%]
test/labeling/preprocess/test_nlp.py F                                   [ 78%]
test/map/test_core.py ....................F.                             [ 87%]
test/slicing/test_monitor.py .                                           [ 88%]
test/slicing/test_slice_combiner.py .......                              [ 91%]
test/slicing/test_sliceaware_classifier.py ...                           [ 92%]
test/slicing/test_utils.py ..                                            [ 93%]
test/slicing/apply/test_sf_applier.py ..                                 [ 94%]
test/slicing/sf/test_core.py ..                                          [ 95%]
test/slicing/sf/test_nlp.py FF                                           [ 96%]
test/synthetic/test_synthetic_data.py ..                                 [ 96%]
test/utils/test_config_utils.py .                                        [ 97%]
test/utils/test_core.py .....                                            [ 99%]
test/utils/test_data_operators.py .                                      [100%]

=================================== FAILURES ===================================
_________ TestPandasApplier.test_lf_applier_pandas_spacy_preprocessor __________

self = <test.labeling.apply.test_lf_applier.TestPandasApplier testMethod=test_lf_applier_pandas_spacy_preprocessor>

    def test_lf_applier_pandas_spacy_preprocessor(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_____ TestPandasApplier.test_lf_applier_pandas_spacy_preprocessor_memoized _____

self = <test.labeling.apply.test_lf_applier.TestPandasApplier testMethod=test_lf_applier_pandas_spacy_preprocessor_memoized>

    def test_lf_applier_pandas_spacy_preprocessor_memoized(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_____________________ TestDaskApplier.test_lf_applier_dask _____________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask>

    def test_lf_applier_dask(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, g])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:500: in get_async
    for key, res_info, failed in queue_get(queue).result():
../purepython/cpython-3.9/Lib/concurrent/futures/_base.py:439: in result
    return self.__get_result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None

    def __get_result(self):
        if self._exception:
            try:
>               raise self._exception
E               concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.

../purepython/cpython-3.9/Lib/concurrent/futures/_base.py:391: BrokenProcessPool
----------------------------- Captured stdout call -----------------------------
============================= test session starts ==============================
platform linux -- Python 3.9.15+, pytest-7.2.0, pluggy-1.0.0
rootdir: /home/user/snorkel, configfile: setup.cfg
plugins: mock-3.10.0, hypothesis-6.56.4, httpbin-1.0.2, cov-4.0.0, time-machine-2.9.0, html-3.2.0, Faker-15.3.4, anyio-3.6.2, flaky-3.7.0, hydra-core-1.3.2, xdist-3.2.1, test-utils-0.0.8, lazy-fixture-0.6.3, docker-1.0.1, xonsh-0.13.4, pylama-8.4.1, dash-2.9.1
collected 233 items

test/analysis/test_error_analysis.py .....                               [  2%]
test/analysis/test_metrics.py ............                               [  7%]
test/analysis/test_scorer.py ........                                    [ 10%]
test/augmentation/apply/test_tf_applier.py ................              [ 17%]
test/augmentation/policy/test_core.py ..                                 [ 18%]
test/augmentation/policy/test_sampling.py ..                             [ 19%]
test/classification/test_classifier_convergence.py .                     [ 19%]
test/classification/test_data.py ..                                      [ 20%]
test/classification/test_loss.py ......                                  [ 23%]
test/classification/test_multitask_classifier.py ..............          [ 29%]
test/classification/test_task.py .                                       [ 29%]
test/classification/test_utils.py ...                                    [ 30%]
test/classification/training/test_trainer.py ..........                  [ 35%]
test/classification/training/loggers/test_checkpointer.py .......        [ 38%]
test/classification/training/loggers/test_log_manager.py .....           [ 40%]
test/classification/training/loggers/test_log_writer.py ...              [ 41%]
test/classification/training/loggers/test_tensorboard_writer.py .        [ 42%]
test/classification/training/schedulers/test_schedulers.py ..            [ 42%]
test/labeling/test_analysis.py ............                              [ 48%]
test/labeling/test_convergence.py .                                      [ 48%]
test/labeling/test_utils.py .                                            [ 48%]
test/labeling/apply/test_lf_applier.py ..........FFFFFFF.FF              [ 57%]
test/labeling/lf/test_core.py ........                                   [ 60%]
test/labeling/lf/test_nlp.py FFF.FFF                                     [ 63%]
test/labeling/model/test_baseline.py ...                                 [ 65%]
test/labeling/model/test_label_model.py ...........................      [ 76%]
test/labeling/model/test_logger.py ...                                   [ 78%]
test/labeling/preprocess/test_nlp.py F                                   [ 78%]
test/map/test_core.py ....................F.                             [ 87%]
test/slicing/test_monitor.py .                                           [ 88%]
test/slicing/test_slice_combiner.py .......                              [ 91%]
test/slicing/test_sliceaware_classifier.py ...                           [ 92%]
test/slicing/test_utils.py ..                                            [ 93%]
test/slicing/apply/test_sf_applier.py ..                                 [ 94%]
test/slicing/sf/test_core.py ..                                          [ 95%]
test/slicing/sf/test_nlp.py FF                                           [ 96%]
test/synthetic/test_synthetic_data.py ..                                 [ 96%]
test/utils/test_config_utils.py .                                        [ 97%]
test/utils/test_core.py .....                                            [ 99%]
test/utils/test_data_operators.py .                                      [100%]

=================================== FAILURES ===================================
_________ TestPandasApplier.test_lf_applier_pandas_spacy_preprocessor __________

self = <test.labeling.apply.test_lf_applier.TestPandasApplier testMethod=test_lf_applier_pandas_spacy_preprocessor>

    def test_lf_applier_pandas_spacy_preprocessor(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_____ TestPandasApplier.test_lf_applier_pandas_spacy_preprocessor_memoized _____

self = <test.labeling.apply.test_lf_applier.TestPandasApplier testMethod=test_lf_applier_pandas_spacy_preprocessor_memoized>

    def test_lf_applier_pandas_spacy_preprocessor_memoized(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_____________________ TestDaskApplier.test_lf_applier_dask _____________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask>

    def test_lf_applier_dask(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, g])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
__________________ TestDaskApplier.test_lf_applier_dask_fault __________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_fault>

    def test_lf_applier_dask_fault(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, f_bad])
        with self.assertRaises(Exception):
            applier.apply(df)
>       L = applier.apply(df, fault_tolerant=True)

test/labeling/apply/test_lf_applier.py:237: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
______________ TestDaskApplier.test_lf_applier_dask_preprocessor _______________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_preprocessor>

    def test_lf_applier_dask_preprocessor(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, fp])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
___________ TestDaskApplier.test_lf_applier_dask_spacy_preprocessor ____________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_spacy_preprocessor>

    @pytest.mark.complex
    def test_lf_applier_dask_spacy_preprocessor(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:265: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______________ TestDaskApplier.test_lf_applier_pandas_parallel ________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_parallel>

    def test_lf_applier_pandas_parallel(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        applier = PandasParallelLFApplier([f, g])
>       L = applier.apply(df, n_parallel=2)

test/labeling/apply/test_lf_applier.py:303: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:98: in apply
    return super().apply(df, scheduler=scheduler, fault_tolerant=fault_tolerant)
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
_________ TestDaskApplier.test_lf_applier_pandas_preprocessor_memoized _________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_preprocessor_memoized>

    def test_lf_applier_pandas_preprocessor_memoized(self) -> None:
        @preprocessor(memoize=True)
        def square_memoize(x: DataPoint) -> DataPoint:
            x.num_squared = x.num**2
            return x
    
        @labeling_function(pre=[square_memoize])
        def fp_memoized(x: DataPoint) -> int:
            return 0 if x.num_squared > 42 else -1
    
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, fp_memoized])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
______ TestDaskApplier.test_lf_applier_pandas_spacy_preprocessor_memoized ______

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_spacy_preprocessor_memoized>

    @pytest.mark.complex
    def test_lf_applier_pandas_spacy_preprocessor_memoized(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:283: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
___________ TestNLPLabelingFunction.test_labeling_function_serialize ___________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_labeling_function_serialize>

    @pytest.mark.complex
    def test_labeling_function_serialize(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
______________ TestNLPLabelingFunction.test_nlp_labeling_function ______________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function>

    def test_nlp_labeling_function(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_________ TestNLPLabelingFunction.test_nlp_labeling_function_decorator _________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_decorator>

    def test_nlp_labeling_function_decorator(self) -> None:
        @nlp_labeling_function(pre=[combine_text])
>       def has_person_mention(x: DataPoint) -> int:

test/labeling/lf/test_nlp.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_________ TestNLPLabelingFunction.test_nlp_labeling_function_memoized __________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_memoized>

    def test_nlp_labeling_function_memoized(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
__________ TestNLPLabelingFunction.test_nlp_labeling_function_raises ___________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_raises>

    def test_nlp_labeling_function_raises(self) -> None:
    
        with self.assertRaisesRegex(ValueError, "different parameters"):
    
            @nlp_labeling_function()
>           def has_person_mention(x: DataPoint) -> int:

test/labeling/lf/test_nlp.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______ TestNLPLabelingFunction.test_nlp_labeling_function_shared_cache ________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_shared_cache>

    def test_nlp_labeling_function_shared_cache(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
________________ TestSpacyPreprocessor.test_spacy_preprocessor _________________

self = <test.labeling.preprocess.test_nlp.TestSpacyPreprocessor testMethod=test_spacy_preprocessor>

    def test_spacy_preprocessor(self) -> None:
        x = SimpleNamespace(text="Jane plays soccer.")
>       preprocessor = SpacyPreprocessor("text", "doc")

test/labeling/preprocess/test_nlp.py:10: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
______________ TestGetHashable.test_get_hashable_series_with_doc _______________

self = <test.map.test_core.TestGetHashable testMethod=test_get_hashable_series_with_doc>

    def test_get_hashable_series_with_doc(self) -> None:
>       nlp = spacy.load("en_core_web_sm")

test/map/test_core.py:400: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______________ TestNLPSlicingFunction.test_nlp_slicing_function _______________

self = <test.slicing.sf.test_nlp.TestNLPSlicingFunction testMethod=test_nlp_slicing_function>

    def test_nlp_slicing_function(self) -> None:
>       sf = NLPSlicingFunction(name="my_sf", f=has_person_mention, pre=[combine_text])

test/slicing/sf/test_nlp.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/slicing/sf/nlp.py:84: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
__________ TestNLPSlicingFunction.test_nlp_slicing_function_decorator __________

self = <test.slicing.sf.test_nlp.TestNLPSlicingFunction testMethod=test_nlp_slicing_function_decorator>

    def test_nlp_slicing_function_decorator(self) -> None:
        @nlp_slicing_function(pre=[combine_text])
>       def has_person_mention(x: DataPoint) -> int:

test/slicing/sf/test_nlp.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/slicing/sf/nlp.py:84: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
=============================== warnings summary ===============================
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/botocore/httpsession.py:41
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/botocore/httpsession.py:41: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680
    from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext

test/classification/training/test_trainer.py::TrainerTest::test_save_load
  /home/user/snorkel/test/classification/training/test_trainer.py:250: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
    if isinstance(dict1_, collections.Mapping):

test/labeling/test_analysis.py::TestAnalysis::test_lf_conflicts
  /home/user/snorkel/snorkel/labeling/analysis.py:264: RuntimeWarning: invalid value encountered in divide
    conflicts /= self.lf_overlaps()

test/labeling/test_analysis.py::TestAnalysis::test_lf_overlaps
  /home/user/snorkel/snorkel/labeling/analysis.py:221: RuntimeWarning: invalid value encountered in divide
    overlaps /= self.lf_coverages()

test/labeling/test_convergence.py: 1 warning
test/labeling/model/test_label_model.py: 52 warnings
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/networkx/algorithms/chordal.py:206: DeprecationWarning: This will return a generator in 3.0.
    warnings.warn(msg, DeprecationWarning)

test/slicing/test_sliceaware_classifier.py::SliceCombinerTest::test_scores_pipeline
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
    _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED test/labeling/apply/test_lf_applier.py::TestPandasApplier::test_lf_applier_pandas_spacy_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestPandasApplier::test_lf_applier_pandas_spacy_preprocessor_memoized
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_fault
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_spacy_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_parallel
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_preprocessor_memoized
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_spacy_preprocessor_memoized
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_labeling_function_serialize
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_decorator
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_memoized
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_raises
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_shared_cache
FAILED test/labeling/preprocess/test_nlp.py::TestSpacyPreprocessor::test_spacy_preprocessor
FAILED test/map/test_core.py::TestGetHashable::test_get_hashable_series_with_doc
FAILED test/slicing/sf/test_nlp.py::TestNLPSlicingFunction::test_nlp_slicing_function
FAILED test/slicing/sf/test_nlp.py::TestNLPSlicingFunction::test_nlp_slicing_function_decorator
=========== 19 failed, 214 passed, 58 warnings in 340.29s (0:05:40) ============
----------------------------- Captured stderr call -----------------------------
/home/user/thefuck-master/pre_run_biend.py:3884: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6C) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3894: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(O6C) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3918: DeprecationWarning: invalid escape sequence \ 
  f.write('$extenion\ set$ & ' + ' & '.join(EXT_SET) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3919: DeprecationWarning: invalid escape sequence \ 
  f.write('$extenion\ event$ & ' + ' & '.join(EXT_EVENT) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4046: DeprecationWarning: invalid escape sequence \_
  d_ = d.replace('_', '\_')
/home/user/thefuck-master/pre_run_biend.py:4057: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6[:10]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4067: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6[10:]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4079: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6ov[:10]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4091: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6ov[10:]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4213: DeprecationWarning: invalid escape sequence \_
  d_ = d.replace('_', '\_')
/home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dash/testing/plugin.py:92: PytestDeprecationWarning: The hookimpl pytest_addhooks uses old-style configuration options (marks or attributes).
Please use the pytest.hookimpl(tryfirst=True) decorator instead
 to configure the hooks.
 See https://docs.pytest.org/en/latest/deprecations.html#configuring-hook-specs-impls-using-markers
  @pytest.mark.tryfirst
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/user/thefuck-master/pre_run_biend.py", line 102, in <module>
    from lark import Lark
ModuleNotFoundError: No module named 'lark'
__________________ TestDaskApplier.test_lf_applier_dask_fault __________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_fault>

    def test_lf_applier_dask_fault(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, f_bad])
        with self.assertRaises(Exception):
            applier.apply(df)
>       L = applier.apply(df, fault_tolerant=True)

test/labeling/apply/test_lf_applier.py:237: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:500: in get_async
    for key, res_info, failed in queue_get(queue).result():
../purepython/cpython-3.9/Lib/concurrent/futures/_base.py:439: in result
    return self.__get_result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None

    def __get_result(self):
        if self._exception:
            try:
>               raise self._exception
E               concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.

../purepython/cpython-3.9/Lib/concurrent/futures/_base.py:391: BrokenProcessPool
----------------------------- Captured stdout call -----------------------------
============================= test session starts ==============================
platform linux -- Python 3.9.15+, pytest-7.2.0, pluggy-1.0.0
rootdir: /home/user/snorkel, configfile: setup.cfg
plugins: mock-3.10.0, hypothesis-6.56.4, httpbin-1.0.2, cov-4.0.0, time-machine-2.9.0, html-3.2.0, Faker-15.3.4, anyio-3.6.2, flaky-3.7.0, hydra-core-1.3.2, xdist-3.2.1, test-utils-0.0.8, lazy-fixture-0.6.3, docker-1.0.1, xonsh-0.13.4, pylama-8.4.1, dash-2.9.1
collected 233 items

test/analysis/test_error_analysis.py .....                               [  2%]
test/analysis/test_metrics.py ............                               [  7%]
test/analysis/test_scorer.py ........                                    [ 10%]
test/augmentation/apply/test_tf_applier.py ................              [ 17%]
test/augmentation/policy/test_core.py ..                                 [ 18%]
test/augmentation/policy/test_sampling.py ..                             [ 19%]
test/classification/test_classifier_convergence.py .                     [ 19%]
test/classification/test_data.py ..                                      [ 20%]
test/classification/test_loss.py ......                                  [ 23%]
test/classification/test_multitask_classifier.py ..............          [ 29%]
test/classification/test_task.py .                                       [ 29%]
test/classification/test_utils.py ...                                    [ 30%]
test/classification/training/test_trainer.py ..........                  [ 35%]
test/classification/training/loggers/test_checkpointer.py .......        [ 38%]
test/classification/training/loggers/test_log_manager.py .....           [ 40%]
test/classification/training/loggers/test_log_writer.py ...              [ 41%]
test/classification/training/loggers/test_tensorboard_writer.py .        [ 42%]
test/classification/training/schedulers/test_schedulers.py ..            [ 42%]
test/labeling/test_analysis.py ............                              [ 48%]
test/labeling/test_convergence.py .                                      [ 48%]
test/labeling/test_utils.py .                                            [ 48%]
test/labeling/apply/test_lf_applier.py ..........FFFFFFF.FF              [ 57%]
test/labeling/lf/test_core.py ........                                   [ 60%]
test/labeling/lf/test_nlp.py FFF.FFF                                     [ 63%]
test/labeling/model/test_baseline.py ...                                 [ 65%]
test/labeling/model/test_label_model.py ...........................      [ 76%]
test/labeling/model/test_logger.py ...                                   [ 78%]
test/labeling/preprocess/test_nlp.py F                                   [ 78%]
test/map/test_core.py ....................F.                             [ 87%]
test/slicing/test_monitor.py .                                           [ 88%]
test/slicing/test_slice_combiner.py .......                              [ 91%]
test/slicing/test_sliceaware_classifier.py ...                           [ 92%]
test/slicing/test_utils.py ..                                            [ 93%]
test/slicing/apply/test_sf_applier.py ..                                 [ 94%]
test/slicing/sf/test_core.py ..                                          [ 95%]
test/slicing/sf/test_nlp.py FF                                           [ 96%]
test/synthetic/test_synthetic_data.py ..                                 [ 96%]
test/utils/test_config_utils.py .                                        [ 97%]
test/utils/test_core.py .....                                            [ 99%]
test/utils/test_data_operators.py .                                      [100%]

=================================== FAILURES ===================================
_________ TestPandasApplier.test_lf_applier_pandas_spacy_preprocessor __________

self = <test.labeling.apply.test_lf_applier.TestPandasApplier testMethod=test_lf_applier_pandas_spacy_preprocessor>

    def test_lf_applier_pandas_spacy_preprocessor(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_____ TestPandasApplier.test_lf_applier_pandas_spacy_preprocessor_memoized _____

self = <test.labeling.apply.test_lf_applier.TestPandasApplier testMethod=test_lf_applier_pandas_spacy_preprocessor_memoized>

    def test_lf_applier_pandas_spacy_preprocessor_memoized(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_____________________ TestDaskApplier.test_lf_applier_dask _____________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask>

    def test_lf_applier_dask(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, g])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
__________________ TestDaskApplier.test_lf_applier_dask_fault __________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_fault>

    def test_lf_applier_dask_fault(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, f_bad])
        with self.assertRaises(Exception):
            applier.apply(df)
>       L = applier.apply(df, fault_tolerant=True)

test/labeling/apply/test_lf_applier.py:237: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
______________ TestDaskApplier.test_lf_applier_dask_preprocessor _______________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_preprocessor>

    def test_lf_applier_dask_preprocessor(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, fp])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
___________ TestDaskApplier.test_lf_applier_dask_spacy_preprocessor ____________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_spacy_preprocessor>

    @pytest.mark.complex
    def test_lf_applier_dask_spacy_preprocessor(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:265: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______________ TestDaskApplier.test_lf_applier_pandas_parallel ________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_parallel>

    def test_lf_applier_pandas_parallel(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        applier = PandasParallelLFApplier([f, g])
>       L = applier.apply(df, n_parallel=2)

test/labeling/apply/test_lf_applier.py:303: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:98: in apply
    return super().apply(df, scheduler=scheduler, fault_tolerant=fault_tolerant)
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
_________ TestDaskApplier.test_lf_applier_pandas_preprocessor_memoized _________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_preprocessor_memoized>

    def test_lf_applier_pandas_preprocessor_memoized(self) -> None:
        @preprocessor(memoize=True)
        def square_memoize(x: DataPoint) -> DataPoint:
            x.num_squared = x.num**2
            return x
    
        @labeling_function(pre=[square_memoize])
        def fp_memoized(x: DataPoint) -> int:
            return 0 if x.num_squared > 42 else -1
    
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, fp_memoized])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
______ TestDaskApplier.test_lf_applier_pandas_spacy_preprocessor_memoized ______

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_spacy_preprocessor_memoized>

    @pytest.mark.complex
    def test_lf_applier_pandas_spacy_preprocessor_memoized(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:283: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
___________ TestNLPLabelingFunction.test_labeling_function_serialize ___________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_labeling_function_serialize>

    @pytest.mark.complex
    def test_labeling_function_serialize(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
______________ TestNLPLabelingFunction.test_nlp_labeling_function ______________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function>

    def test_nlp_labeling_function(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_________ TestNLPLabelingFunction.test_nlp_labeling_function_decorator _________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_decorator>

    def test_nlp_labeling_function_decorator(self) -> None:
        @nlp_labeling_function(pre=[combine_text])
>       def has_person_mention(x: DataPoint) -> int:

test/labeling/lf/test_nlp.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_________ TestNLPLabelingFunction.test_nlp_labeling_function_memoized __________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_memoized>

    def test_nlp_labeling_function_memoized(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
__________ TestNLPLabelingFunction.test_nlp_labeling_function_raises ___________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_raises>

    def test_nlp_labeling_function_raises(self) -> None:
    
        with self.assertRaisesRegex(ValueError, "different parameters"):
    
            @nlp_labeling_function()
>           def has_person_mention(x: DataPoint) -> int:

test/labeling/lf/test_nlp.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______ TestNLPLabelingFunction.test_nlp_labeling_function_shared_cache ________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_shared_cache>

    def test_nlp_labeling_function_shared_cache(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
________________ TestSpacyPreprocessor.test_spacy_preprocessor _________________

self = <test.labeling.preprocess.test_nlp.TestSpacyPreprocessor testMethod=test_spacy_preprocessor>

    def test_spacy_preprocessor(self) -> None:
        x = SimpleNamespace(text="Jane plays soccer.")
>       preprocessor = SpacyPreprocessor("text", "doc")

test/labeling/preprocess/test_nlp.py:10: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
______________ TestGetHashable.test_get_hashable_series_with_doc _______________

self = <test.map.test_core.TestGetHashable testMethod=test_get_hashable_series_with_doc>

    def test_get_hashable_series_with_doc(self) -> None:
>       nlp = spacy.load("en_core_web_sm")

test/map/test_core.py:400: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______________ TestNLPSlicingFunction.test_nlp_slicing_function _______________

self = <test.slicing.sf.test_nlp.TestNLPSlicingFunction testMethod=test_nlp_slicing_function>

    def test_nlp_slicing_function(self) -> None:
>       sf = NLPSlicingFunction(name="my_sf", f=has_person_mention, pre=[combine_text])

test/slicing/sf/test_nlp.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/slicing/sf/nlp.py:84: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
__________ TestNLPSlicingFunction.test_nlp_slicing_function_decorator __________

self = <test.slicing.sf.test_nlp.TestNLPSlicingFunction testMethod=test_nlp_slicing_function_decorator>

    def test_nlp_slicing_function_decorator(self) -> None:
        @nlp_slicing_function(pre=[combine_text])
>       def has_person_mention(x: DataPoint) -> int:

test/slicing/sf/test_nlp.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/slicing/sf/nlp.py:84: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
=============================== warnings summary ===============================
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/botocore/httpsession.py:41
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/botocore/httpsession.py:41: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680
    from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext

test/classification/training/test_trainer.py::TrainerTest::test_save_load
  /home/user/snorkel/test/classification/training/test_trainer.py:250: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
    if isinstance(dict1_, collections.Mapping):

test/labeling/test_analysis.py::TestAnalysis::test_lf_conflicts
  /home/user/snorkel/snorkel/labeling/analysis.py:264: RuntimeWarning: invalid value encountered in divide
    conflicts /= self.lf_overlaps()

test/labeling/test_analysis.py::TestAnalysis::test_lf_overlaps
  /home/user/snorkel/snorkel/labeling/analysis.py:221: RuntimeWarning: invalid value encountered in divide
    overlaps /= self.lf_coverages()

test/labeling/test_convergence.py: 1 warning
test/labeling/model/test_label_model.py: 52 warnings
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/networkx/algorithms/chordal.py:206: DeprecationWarning: This will return a generator in 3.0.
    warnings.warn(msg, DeprecationWarning)

test/slicing/test_sliceaware_classifier.py::SliceCombinerTest::test_scores_pipeline
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
    _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED test/labeling/apply/test_lf_applier.py::TestPandasApplier::test_lf_applier_pandas_spacy_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestPandasApplier::test_lf_applier_pandas_spacy_preprocessor_memoized
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_fault
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_spacy_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_parallel
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_preprocessor_memoized
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_spacy_preprocessor_memoized
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_labeling_function_serialize
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_decorator
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_memoized
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_raises
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_shared_cache
FAILED test/labeling/preprocess/test_nlp.py::TestSpacyPreprocessor::test_spacy_preprocessor
FAILED test/map/test_core.py::TestGetHashable::test_get_hashable_series_with_doc
FAILED test/slicing/sf/test_nlp.py::TestNLPSlicingFunction::test_nlp_slicing_function
FAILED test/slicing/sf/test_nlp.py::TestNLPSlicingFunction::test_nlp_slicing_function_decorator
=========== 19 failed, 214 passed, 58 warnings in 278.15s (0:04:38) ============
----------------------------- Captured stderr call -----------------------------
/home/user/thefuck-master/pre_run_biend.py:3884: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6C) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3894: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(O6C) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3918: DeprecationWarning: invalid escape sequence \ 
  f.write('$extenion\ set$ & ' + ' & '.join(EXT_SET) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3919: DeprecationWarning: invalid escape sequence \ 
  f.write('$extenion\ event$ & ' + ' & '.join(EXT_EVENT) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4046: DeprecationWarning: invalid escape sequence \_
  d_ = d.replace('_', '\_')
/home/user/thefuck-master/pre_run_biend.py:4057: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6[:10]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4067: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6[10:]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4079: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6ov[:10]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4091: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6ov[10:]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4213: DeprecationWarning: invalid escape sequence \_
  d_ = d.replace('_', '\_')
/home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dash/testing/plugin.py:92: PytestDeprecationWarning: The hookimpl pytest_addhooks uses old-style configuration options (marks or attributes).
Please use the pytest.hookimpl(tryfirst=True) decorator instead
 to configure the hooks.
 See https://docs.pytest.org/en/latest/deprecations.html#configuring-hook-specs-impls-using-markers
  @pytest.mark.tryfirst
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/user/thefuck-master/pre_run_biend.py", line 102, in <module>
    from lark import Lark
ModuleNotFoundError: No module named 'lark'
______________ TestDaskApplier.test_lf_applier_dask_preprocessor _______________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_preprocessor>

    def test_lf_applier_dask_preprocessor(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, fp])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:500: in get_async
    for key, res_info, failed in queue_get(queue).result():
../purepython/cpython-3.9/Lib/concurrent/futures/_base.py:439: in result
    return self.__get_result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None

    def __get_result(self):
        if self._exception:
            try:
>               raise self._exception
E               concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.

../purepython/cpython-3.9/Lib/concurrent/futures/_base.py:391: BrokenProcessPool
----------------------------- Captured stdout call -----------------------------
============================= test session starts ==============================
platform linux -- Python 3.9.15+, pytest-7.2.0, pluggy-1.0.0
rootdir: /home/user/snorkel, configfile: setup.cfg
plugins: mock-3.10.0, hypothesis-6.56.4, httpbin-1.0.2, cov-4.0.0, time-machine-2.9.0, html-3.2.0, Faker-15.3.4, anyio-3.6.2, flaky-3.7.0, hydra-core-1.3.2, xdist-3.2.1, test-utils-0.0.8, lazy-fixture-0.6.3, docker-1.0.1, xonsh-0.13.4, pylama-8.4.1, dash-2.9.1
collected 233 items

test/analysis/test_error_analysis.py .....                               [  2%]
test/analysis/test_metrics.py ............                               [  7%]
test/analysis/test_scorer.py ........                                    [ 10%]
test/augmentation/apply/test_tf_applier.py ................              [ 17%]
test/augmentation/policy/test_core.py ..                                 [ 18%]
test/augmentation/policy/test_sampling.py ..                             [ 19%]
test/classification/test_classifier_convergence.py .                     [ 19%]
test/classification/test_data.py ..                                      [ 20%]
test/classification/test_loss.py ......                                  [ 23%]
test/classification/test_multitask_classifier.py ..............          [ 29%]
test/classification/test_task.py .                                       [ 29%]
test/classification/test_utils.py ...                                    [ 30%]
test/classification/training/test_trainer.py ..........                  [ 35%]
test/classification/training/loggers/test_checkpointer.py .......        [ 38%]
test/classification/training/loggers/test_log_manager.py .....           [ 40%]
test/classification/training/loggers/test_log_writer.py ...              [ 41%]
test/classification/training/loggers/test_tensorboard_writer.py .        [ 42%]
test/classification/training/schedulers/test_schedulers.py ..            [ 42%]
test/labeling/test_analysis.py ............                              [ 48%]
test/labeling/test_convergence.py .                                      [ 48%]
test/labeling/test_utils.py .                                            [ 48%]
test/labeling/apply/test_lf_applier.py ..........FFFFFFF.FF              [ 57%]
test/labeling/lf/test_core.py ........                                   [ 60%]
test/labeling/lf/test_nlp.py FFF.FFF                                     [ 63%]
test/labeling/model/test_baseline.py ...                                 [ 65%]
test/labeling/model/test_label_model.py ...........................      [ 76%]
test/labeling/model/test_logger.py ...                                   [ 78%]
test/labeling/preprocess/test_nlp.py F                                   [ 78%]
test/map/test_core.py ....................F.                             [ 87%]
test/slicing/test_monitor.py .                                           [ 88%]
test/slicing/test_slice_combiner.py .......                              [ 91%]
test/slicing/test_sliceaware_classifier.py ...                           [ 92%]
test/slicing/test_utils.py ..                                            [ 93%]
test/slicing/apply/test_sf_applier.py ..                                 [ 94%]
test/slicing/sf/test_core.py ..                                          [ 95%]
test/slicing/sf/test_nlp.py FF                                           [ 96%]
test/synthetic/test_synthetic_data.py ..                                 [ 96%]
test/utils/test_config_utils.py .                                        [ 97%]
test/utils/test_core.py .....                                            [ 99%]
test/utils/test_data_operators.py .                                      [100%]

=================================== FAILURES ===================================
_________ TestPandasApplier.test_lf_applier_pandas_spacy_preprocessor __________

self = <test.labeling.apply.test_lf_applier.TestPandasApplier testMethod=test_lf_applier_pandas_spacy_preprocessor>

    def test_lf_applier_pandas_spacy_preprocessor(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_____ TestPandasApplier.test_lf_applier_pandas_spacy_preprocessor_memoized _____

self = <test.labeling.apply.test_lf_applier.TestPandasApplier testMethod=test_lf_applier_pandas_spacy_preprocessor_memoized>

    def test_lf_applier_pandas_spacy_preprocessor_memoized(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_____________________ TestDaskApplier.test_lf_applier_dask _____________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask>

    def test_lf_applier_dask(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, g])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
__________________ TestDaskApplier.test_lf_applier_dask_fault __________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_fault>

    def test_lf_applier_dask_fault(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, f_bad])
        with self.assertRaises(Exception):
            applier.apply(df)
>       L = applier.apply(df, fault_tolerant=True)

test/labeling/apply/test_lf_applier.py:237: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
______________ TestDaskApplier.test_lf_applier_dask_preprocessor _______________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_preprocessor>

    def test_lf_applier_dask_preprocessor(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, fp])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
___________ TestDaskApplier.test_lf_applier_dask_spacy_preprocessor ____________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_spacy_preprocessor>

    @pytest.mark.complex
    def test_lf_applier_dask_spacy_preprocessor(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:265: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______________ TestDaskApplier.test_lf_applier_pandas_parallel ________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_parallel>

    def test_lf_applier_pandas_parallel(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        applier = PandasParallelLFApplier([f, g])
>       L = applier.apply(df, n_parallel=2)

test/labeling/apply/test_lf_applier.py:303: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:98: in apply
    return super().apply(df, scheduler=scheduler, fault_tolerant=fault_tolerant)
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
_________ TestDaskApplier.test_lf_applier_pandas_preprocessor_memoized _________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_preprocessor_memoized>

    def test_lf_applier_pandas_preprocessor_memoized(self) -> None:
        @preprocessor(memoize=True)
        def square_memoize(x: DataPoint) -> DataPoint:
            x.num_squared = x.num**2
            return x
    
        @labeling_function(pre=[square_memoize])
        def fp_memoized(x: DataPoint) -> int:
            return 0 if x.num_squared > 42 else -1
    
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, fp_memoized])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
______ TestDaskApplier.test_lf_applier_pandas_spacy_preprocessor_memoized ______

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_spacy_preprocessor_memoized>

    @pytest.mark.complex
    def test_lf_applier_pandas_spacy_preprocessor_memoized(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:283: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
___________ TestNLPLabelingFunction.test_labeling_function_serialize ___________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_labeling_function_serialize>

    @pytest.mark.complex
    def test_labeling_function_serialize(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
______________ TestNLPLabelingFunction.test_nlp_labeling_function ______________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function>

    def test_nlp_labeling_function(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_________ TestNLPLabelingFunction.test_nlp_labeling_function_decorator _________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_decorator>

    def test_nlp_labeling_function_decorator(self) -> None:
        @nlp_labeling_function(pre=[combine_text])
>       def has_person_mention(x: DataPoint) -> int:

test/labeling/lf/test_nlp.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_________ TestNLPLabelingFunction.test_nlp_labeling_function_memoized __________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_memoized>

    def test_nlp_labeling_function_memoized(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
__________ TestNLPLabelingFunction.test_nlp_labeling_function_raises ___________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_raises>

    def test_nlp_labeling_function_raises(self) -> None:
    
        with self.assertRaisesRegex(ValueError, "different parameters"):
    
            @nlp_labeling_function()
>           def has_person_mention(x: DataPoint) -> int:

test/labeling/lf/test_nlp.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______ TestNLPLabelingFunction.test_nlp_labeling_function_shared_cache ________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_shared_cache>

    def test_nlp_labeling_function_shared_cache(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
________________ TestSpacyPreprocessor.test_spacy_preprocessor _________________

self = <test.labeling.preprocess.test_nlp.TestSpacyPreprocessor testMethod=test_spacy_preprocessor>

    def test_spacy_preprocessor(self) -> None:
        x = SimpleNamespace(text="Jane plays soccer.")
>       preprocessor = SpacyPreprocessor("text", "doc")

test/labeling/preprocess/test_nlp.py:10: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
______________ TestGetHashable.test_get_hashable_series_with_doc _______________

self = <test.map.test_core.TestGetHashable testMethod=test_get_hashable_series_with_doc>

    def test_get_hashable_series_with_doc(self) -> None:
>       nlp = spacy.load("en_core_web_sm")

test/map/test_core.py:400: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______________ TestNLPSlicingFunction.test_nlp_slicing_function _______________

self = <test.slicing.sf.test_nlp.TestNLPSlicingFunction testMethod=test_nlp_slicing_function>

    def test_nlp_slicing_function(self) -> None:
>       sf = NLPSlicingFunction(name="my_sf", f=has_person_mention, pre=[combine_text])

test/slicing/sf/test_nlp.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/slicing/sf/nlp.py:84: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
__________ TestNLPSlicingFunction.test_nlp_slicing_function_decorator __________

self = <test.slicing.sf.test_nlp.TestNLPSlicingFunction testMethod=test_nlp_slicing_function_decorator>

    def test_nlp_slicing_function_decorator(self) -> None:
        @nlp_slicing_function(pre=[combine_text])
>       def has_person_mention(x: DataPoint) -> int:

test/slicing/sf/test_nlp.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/slicing/sf/nlp.py:84: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
=============================== warnings summary ===============================
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/botocore/httpsession.py:41
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/botocore/httpsession.py:41: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680
    from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext

test/classification/training/test_trainer.py::TrainerTest::test_save_load
  /home/user/snorkel/test/classification/training/test_trainer.py:250: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
    if isinstance(dict1_, collections.Mapping):

test/labeling/test_analysis.py::TestAnalysis::test_lf_conflicts
  /home/user/snorkel/snorkel/labeling/analysis.py:264: RuntimeWarning: invalid value encountered in divide
    conflicts /= self.lf_overlaps()

test/labeling/test_analysis.py::TestAnalysis::test_lf_overlaps
  /home/user/snorkel/snorkel/labeling/analysis.py:221: RuntimeWarning: invalid value encountered in divide
    overlaps /= self.lf_coverages()

test/labeling/test_convergence.py: 1 warning
test/labeling/model/test_label_model.py: 52 warnings
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/networkx/algorithms/chordal.py:206: DeprecationWarning: This will return a generator in 3.0.
    warnings.warn(msg, DeprecationWarning)

test/slicing/test_sliceaware_classifier.py::SliceCombinerTest::test_scores_pipeline
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
    _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED test/labeling/apply/test_lf_applier.py::TestPandasApplier::test_lf_applier_pandas_spacy_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestPandasApplier::test_lf_applier_pandas_spacy_preprocessor_memoized
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_fault
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_spacy_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_parallel
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_preprocessor_memoized
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_spacy_preprocessor_memoized
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_labeling_function_serialize
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_decorator
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_memoized
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_raises
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_shared_cache
FAILED test/labeling/preprocess/test_nlp.py::TestSpacyPreprocessor::test_spacy_preprocessor
FAILED test/map/test_core.py::TestGetHashable::test_get_hashable_series_with_doc
FAILED test/slicing/sf/test_nlp.py::TestNLPSlicingFunction::test_nlp_slicing_function
FAILED test/slicing/sf/test_nlp.py::TestNLPSlicingFunction::test_nlp_slicing_function_decorator
=========== 19 failed, 214 passed, 58 warnings in 289.00s (0:04:48) ============
----------------------------- Captured stderr call -----------------------------
/home/user/thefuck-master/pre_run_biend.py:3884: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6C) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3894: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(O6C) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3918: DeprecationWarning: invalid escape sequence \ 
  f.write('$extenion\ set$ & ' + ' & '.join(EXT_SET) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3919: DeprecationWarning: invalid escape sequence \ 
  f.write('$extenion\ event$ & ' + ' & '.join(EXT_EVENT) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4046: DeprecationWarning: invalid escape sequence \_
  d_ = d.replace('_', '\_')
/home/user/thefuck-master/pre_run_biend.py:4057: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6[:10]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4067: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6[10:]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4079: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6ov[:10]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4091: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6ov[10:]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4213: DeprecationWarning: invalid escape sequence \_
  d_ = d.replace('_', '\_')
/home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dash/testing/plugin.py:92: PytestDeprecationWarning: The hookimpl pytest_addhooks uses old-style configuration options (marks or attributes).
Please use the pytest.hookimpl(tryfirst=True) decorator instead
 to configure the hooks.
 See https://docs.pytest.org/en/latest/deprecations.html#configuring-hook-specs-impls-using-markers
  @pytest.mark.tryfirst
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/user/thefuck-master/pre_run_biend.py", line 102, in <module>
    from lark import Lark
ModuleNotFoundError: No module named 'lark'
___________ TestDaskApplier.test_lf_applier_dask_spacy_preprocessor ____________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_spacy_preprocessor>

    @pytest.mark.complex
    def test_lf_applier_dask_spacy_preprocessor(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:265: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______________ TestDaskApplier.test_lf_applier_pandas_parallel ________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_parallel>

    def test_lf_applier_pandas_parallel(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        applier = PandasParallelLFApplier([f, g])
>       L = applier.apply(df, n_parallel=2)

test/labeling/apply/test_lf_applier.py:303: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/apply/dask.py:98: in apply
    return super().apply(df, scheduler=scheduler, fault_tolerant=fault_tolerant)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:500: in get_async
    for key, res_info, failed in queue_get(queue).result():
../purepython/cpython-3.9/Lib/concurrent/futures/_base.py:439: in result
    return self.__get_result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None

    def __get_result(self):
        if self._exception:
            try:
>               raise self._exception
E               concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.

../purepython/cpython-3.9/Lib/concurrent/futures/_base.py:391: BrokenProcessPool
----------------------------- Captured stdout call -----------------------------
============================= test session starts ==============================
platform linux -- Python 3.9.15+, pytest-7.2.0, pluggy-1.0.0
rootdir: /home/user/snorkel, configfile: setup.cfg
plugins: mock-3.10.0, hypothesis-6.56.4, httpbin-1.0.2, cov-4.0.0, time-machine-2.9.0, html-3.2.0, Faker-15.3.4, anyio-3.6.2, flaky-3.7.0, hydra-core-1.3.2, xdist-3.2.1, test-utils-0.0.8, lazy-fixture-0.6.3, docker-1.0.1, xonsh-0.13.4, pylama-8.4.1, dash-2.9.1
collected 233 items

test/analysis/test_error_analysis.py .....                               [  2%]
test/analysis/test_metrics.py ............                               [  7%]
test/analysis/test_scorer.py ........                                    [ 10%]
test/augmentation/apply/test_tf_applier.py ................              [ 17%]
test/augmentation/policy/test_core.py ..                                 [ 18%]
test/augmentation/policy/test_sampling.py ..                             [ 19%]
test/classification/test_classifier_convergence.py .                     [ 19%]
test/classification/test_data.py ..                                      [ 20%]
test/classification/test_loss.py ......                                  [ 23%]
test/classification/test_multitask_classifier.py ..............          [ 29%]
test/classification/test_task.py .                                       [ 29%]
test/classification/test_utils.py ...                                    [ 30%]
test/classification/training/test_trainer.py ..........                  [ 35%]
test/classification/training/loggers/test_checkpointer.py .......        [ 38%]
test/classification/training/loggers/test_log_manager.py .....           [ 40%]
test/classification/training/loggers/test_log_writer.py ...              [ 41%]
test/classification/training/loggers/test_tensorboard_writer.py .        [ 42%]
test/classification/training/schedulers/test_schedulers.py ..            [ 42%]
test/labeling/test_analysis.py ............                              [ 48%]
test/labeling/test_convergence.py .                                      [ 48%]
test/labeling/test_utils.py .                                            [ 48%]
test/labeling/apply/test_lf_applier.py ..........FFFFFFF.FF              [ 57%]
test/labeling/lf/test_core.py ........                                   [ 60%]
test/labeling/lf/test_nlp.py FFF.FFF                                     [ 63%]
test/labeling/model/test_baseline.py ...                                 [ 65%]
test/labeling/model/test_label_model.py ...........................      [ 76%]
test/labeling/model/test_logger.py ...                                   [ 78%]
test/labeling/preprocess/test_nlp.py F                                   [ 78%]
test/map/test_core.py ....................F.                             [ 87%]
test/slicing/test_monitor.py .                                           [ 88%]
test/slicing/test_slice_combiner.py .......                              [ 91%]
test/slicing/test_sliceaware_classifier.py ...                           [ 92%]
test/slicing/test_utils.py ..                                            [ 93%]
test/slicing/apply/test_sf_applier.py ..                                 [ 94%]
test/slicing/sf/test_core.py ..                                          [ 95%]
test/slicing/sf/test_nlp.py FF                                           [ 96%]
test/synthetic/test_synthetic_data.py ..                                 [ 96%]
test/utils/test_config_utils.py .                                        [ 97%]
test/utils/test_core.py .....                                            [ 99%]
test/utils/test_data_operators.py .                                      [100%]

=================================== FAILURES ===================================
_________ TestPandasApplier.test_lf_applier_pandas_spacy_preprocessor __________

self = <test.labeling.apply.test_lf_applier.TestPandasApplier testMethod=test_lf_applier_pandas_spacy_preprocessor>

    def test_lf_applier_pandas_spacy_preprocessor(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_____ TestPandasApplier.test_lf_applier_pandas_spacy_preprocessor_memoized _____

self = <test.labeling.apply.test_lf_applier.TestPandasApplier testMethod=test_lf_applier_pandas_spacy_preprocessor_memoized>

    def test_lf_applier_pandas_spacy_preprocessor_memoized(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_____________________ TestDaskApplier.test_lf_applier_dask _____________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask>

    def test_lf_applier_dask(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, g])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
__________________ TestDaskApplier.test_lf_applier_dask_fault __________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_fault>

    def test_lf_applier_dask_fault(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, f_bad])
        with self.assertRaises(Exception):
            applier.apply(df)
>       L = applier.apply(df, fault_tolerant=True)

test/labeling/apply/test_lf_applier.py:237: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
______________ TestDaskApplier.test_lf_applier_dask_preprocessor _______________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_preprocessor>

    def test_lf_applier_dask_preprocessor(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, fp])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
___________ TestDaskApplier.test_lf_applier_dask_spacy_preprocessor ____________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_spacy_preprocessor>

    @pytest.mark.complex
    def test_lf_applier_dask_spacy_preprocessor(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:265: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______________ TestDaskApplier.test_lf_applier_pandas_parallel ________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_parallel>

    def test_lf_applier_pandas_parallel(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        applier = PandasParallelLFApplier([f, g])
>       L = applier.apply(df, n_parallel=2)

test/labeling/apply/test_lf_applier.py:303: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:98: in apply
    return super().apply(df, scheduler=scheduler, fault_tolerant=fault_tolerant)
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
_________ TestDaskApplier.test_lf_applier_pandas_preprocessor_memoized _________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_preprocessor_memoized>

    def test_lf_applier_pandas_preprocessor_memoized(self) -> None:
        @preprocessor(memoize=True)
        def square_memoize(x: DataPoint) -> DataPoint:
            x.num_squared = x.num**2
            return x
    
        @labeling_function(pre=[square_memoize])
        def fp_memoized(x: DataPoint) -> int:
            return 0 if x.num_squared > 42 else -1
    
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, fp_memoized])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
______ TestDaskApplier.test_lf_applier_pandas_spacy_preprocessor_memoized ______

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_spacy_preprocessor_memoized>

    @pytest.mark.complex
    def test_lf_applier_pandas_spacy_preprocessor_memoized(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:283: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
___________ TestNLPLabelingFunction.test_labeling_function_serialize ___________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_labeling_function_serialize>

    @pytest.mark.complex
    def test_labeling_function_serialize(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
______________ TestNLPLabelingFunction.test_nlp_labeling_function ______________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function>

    def test_nlp_labeling_function(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_________ TestNLPLabelingFunction.test_nlp_labeling_function_decorator _________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_decorator>

    def test_nlp_labeling_function_decorator(self) -> None:
        @nlp_labeling_function(pre=[combine_text])
>       def has_person_mention(x: DataPoint) -> int:

test/labeling/lf/test_nlp.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_________ TestNLPLabelingFunction.test_nlp_labeling_function_memoized __________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_memoized>

    def test_nlp_labeling_function_memoized(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
__________ TestNLPLabelingFunction.test_nlp_labeling_function_raises ___________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_raises>

    def test_nlp_labeling_function_raises(self) -> None:
    
        with self.assertRaisesRegex(ValueError, "different parameters"):
    
            @nlp_labeling_function()
>           def has_person_mention(x: DataPoint) -> int:

test/labeling/lf/test_nlp.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______ TestNLPLabelingFunction.test_nlp_labeling_function_shared_cache ________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_shared_cache>

    def test_nlp_labeling_function_shared_cache(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
________________ TestSpacyPreprocessor.test_spacy_preprocessor _________________

self = <test.labeling.preprocess.test_nlp.TestSpacyPreprocessor testMethod=test_spacy_preprocessor>

    def test_spacy_preprocessor(self) -> None:
        x = SimpleNamespace(text="Jane plays soccer.")
>       preprocessor = SpacyPreprocessor("text", "doc")

test/labeling/preprocess/test_nlp.py:10: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
______________ TestGetHashable.test_get_hashable_series_with_doc _______________

self = <test.map.test_core.TestGetHashable testMethod=test_get_hashable_series_with_doc>

    def test_get_hashable_series_with_doc(self) -> None:
>       nlp = spacy.load("en_core_web_sm")

test/map/test_core.py:400: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______________ TestNLPSlicingFunction.test_nlp_slicing_function _______________

self = <test.slicing.sf.test_nlp.TestNLPSlicingFunction testMethod=test_nlp_slicing_function>

    def test_nlp_slicing_function(self) -> None:
>       sf = NLPSlicingFunction(name="my_sf", f=has_person_mention, pre=[combine_text])

test/slicing/sf/test_nlp.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/slicing/sf/nlp.py:84: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
__________ TestNLPSlicingFunction.test_nlp_slicing_function_decorator __________

self = <test.slicing.sf.test_nlp.TestNLPSlicingFunction testMethod=test_nlp_slicing_function_decorator>

    def test_nlp_slicing_function_decorator(self) -> None:
        @nlp_slicing_function(pre=[combine_text])
>       def has_person_mention(x: DataPoint) -> int:

test/slicing/sf/test_nlp.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/slicing/sf/nlp.py:84: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
=============================== warnings summary ===============================
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/botocore/httpsession.py:41
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/botocore/httpsession.py:41: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680
    from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext

test/classification/training/test_trainer.py::TrainerTest::test_save_load
  /home/user/snorkel/test/classification/training/test_trainer.py:250: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
    if isinstance(dict1_, collections.Mapping):

test/labeling/test_analysis.py::TestAnalysis::test_lf_conflicts
  /home/user/snorkel/snorkel/labeling/analysis.py:264: RuntimeWarning: invalid value encountered in divide
    conflicts /= self.lf_overlaps()

test/labeling/test_analysis.py::TestAnalysis::test_lf_overlaps
  /home/user/snorkel/snorkel/labeling/analysis.py:221: RuntimeWarning: invalid value encountered in divide
    overlaps /= self.lf_coverages()

test/labeling/test_convergence.py: 1 warning
test/labeling/model/test_label_model.py: 52 warnings
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/networkx/algorithms/chordal.py:206: DeprecationWarning: This will return a generator in 3.0.
    warnings.warn(msg, DeprecationWarning)

test/slicing/test_sliceaware_classifier.py::SliceCombinerTest::test_scores_pipeline
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
    _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED test/labeling/apply/test_lf_applier.py::TestPandasApplier::test_lf_applier_pandas_spacy_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestPandasApplier::test_lf_applier_pandas_spacy_preprocessor_memoized
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_fault
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_spacy_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_parallel
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_preprocessor_memoized
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_spacy_preprocessor_memoized
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_labeling_function_serialize
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_decorator
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_memoized
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_raises
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_shared_cache
FAILED test/labeling/preprocess/test_nlp.py::TestSpacyPreprocessor::test_spacy_preprocessor
FAILED test/map/test_core.py::TestGetHashable::test_get_hashable_series_with_doc
FAILED test/slicing/sf/test_nlp.py::TestNLPSlicingFunction::test_nlp_slicing_function
FAILED test/slicing/sf/test_nlp.py::TestNLPSlicingFunction::test_nlp_slicing_function_decorator
=========== 19 failed, 214 passed, 58 warnings in 288.82s (0:04:48) ============
----------------------------- Captured stderr call -----------------------------
/home/user/thefuck-master/pre_run_biend.py:3884: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6C) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3894: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(O6C) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3918: DeprecationWarning: invalid escape sequence \ 
  f.write('$extenion\ set$ & ' + ' & '.join(EXT_SET) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3919: DeprecationWarning: invalid escape sequence \ 
  f.write('$extenion\ event$ & ' + ' & '.join(EXT_EVENT) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4046: DeprecationWarning: invalid escape sequence \_
  d_ = d.replace('_', '\_')
/home/user/thefuck-master/pre_run_biend.py:4057: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6[:10]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4067: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6[10:]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4079: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6ov[:10]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4091: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6ov[10:]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4213: DeprecationWarning: invalid escape sequence \_
  d_ = d.replace('_', '\_')
/home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dash/testing/plugin.py:92: PytestDeprecationWarning: The hookimpl pytest_addhooks uses old-style configuration options (marks or attributes).
Please use the pytest.hookimpl(tryfirst=True) decorator instead
 to configure the hooks.
 See https://docs.pytest.org/en/latest/deprecations.html#configuring-hook-specs-impls-using-markers
  @pytest.mark.tryfirst
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/user/thefuck-master/pre_run_biend.py", line 102, in <module>
    from lark import Lark
ModuleNotFoundError: No module named 'lark'
_________ TestDaskApplier.test_lf_applier_pandas_preprocessor_memoized _________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_preprocessor_memoized>

    def test_lf_applier_pandas_preprocessor_memoized(self) -> None:
        @preprocessor(memoize=True)
        def square_memoize(x: DataPoint) -> DataPoint:
            x.num_squared = x.num**2
            return x
    
        @labeling_function(pre=[square_memoize])
        def fp_memoized(x: DataPoint) -> int:
            return 0 if x.num_squared > 42 else -1
    
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, fp_memoized])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:500: in get_async
    for key, res_info, failed in queue_get(queue).result():
../purepython/cpython-3.9/Lib/concurrent/futures/_base.py:439: in result
    return self.__get_result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None

    def __get_result(self):
        if self._exception:
            try:
>               raise self._exception
E               concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.

../purepython/cpython-3.9/Lib/concurrent/futures/_base.py:391: BrokenProcessPool
----------------------------- Captured stdout call -----------------------------
============================= test session starts ==============================
platform linux -- Python 3.9.15+, pytest-7.2.0, pluggy-1.0.0
rootdir: /home/user/snorkel, configfile: setup.cfg
plugins: mock-3.10.0, hypothesis-6.56.4, httpbin-1.0.2, cov-4.0.0, time-machine-2.9.0, html-3.2.0, Faker-15.3.4, anyio-3.6.2, flaky-3.7.0, hydra-core-1.3.2, xdist-3.2.1, test-utils-0.0.8, lazy-fixture-0.6.3, docker-1.0.1, xonsh-0.13.4, pylama-8.4.1, dash-2.9.1
collected 233 items

test/analysis/test_error_analysis.py .....                               [  2%]
test/analysis/test_metrics.py ............                               [  7%]
test/analysis/test_scorer.py ........                                    [ 10%]
test/augmentation/apply/test_tf_applier.py ................              [ 17%]
test/augmentation/policy/test_core.py ..                                 [ 18%]
test/augmentation/policy/test_sampling.py ..                             [ 19%]
test/classification/test_classifier_convergence.py .                     [ 19%]
test/classification/test_data.py ..                                      [ 20%]
test/classification/test_loss.py ......                                  [ 23%]
test/classification/test_multitask_classifier.py ..............          [ 29%]
test/classification/test_task.py .                                       [ 29%]
test/classification/test_utils.py ...                                    [ 30%]
test/classification/training/test_trainer.py ..........                  [ 35%]
test/classification/training/loggers/test_checkpointer.py .......        [ 38%]
test/classification/training/loggers/test_log_manager.py .....           [ 40%]
test/classification/training/loggers/test_log_writer.py ...              [ 41%]
test/classification/training/loggers/test_tensorboard_writer.py .        [ 42%]
test/classification/training/schedulers/test_schedulers.py ..            [ 42%]
test/labeling/test_analysis.py ............                              [ 48%]
test/labeling/test_convergence.py .                                      [ 48%]
test/labeling/test_utils.py .                                            [ 48%]
test/labeling/apply/test_lf_applier.py ..........FFFFFFF.FF              [ 57%]
test/labeling/lf/test_core.py ........                                   [ 60%]
test/labeling/lf/test_nlp.py FFF.FFF                                     [ 63%]
test/labeling/model/test_baseline.py ...                                 [ 65%]
test/labeling/model/test_label_model.py ...........................      [ 76%]
test/labeling/model/test_logger.py ...                                   [ 78%]
test/labeling/preprocess/test_nlp.py F                                   [ 78%]
test/map/test_core.py ....................F.                             [ 87%]
test/slicing/test_monitor.py .                                           [ 88%]
test/slicing/test_slice_combiner.py .......                              [ 91%]
test/slicing/test_sliceaware_classifier.py ...                           [ 92%]
test/slicing/test_utils.py ..                                            [ 93%]
test/slicing/apply/test_sf_applier.py ..                                 [ 94%]
test/slicing/sf/test_core.py ..                                          [ 95%]
test/slicing/sf/test_nlp.py FF                                           [ 96%]
test/synthetic/test_synthetic_data.py ..                                 [ 96%]
test/utils/test_config_utils.py .                                        [ 97%]
test/utils/test_core.py .....                                            [ 99%]
test/utils/test_data_operators.py .                                      [100%]

=================================== FAILURES ===================================
_________ TestPandasApplier.test_lf_applier_pandas_spacy_preprocessor __________

self = <test.labeling.apply.test_lf_applier.TestPandasApplier testMethod=test_lf_applier_pandas_spacy_preprocessor>

    def test_lf_applier_pandas_spacy_preprocessor(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_____ TestPandasApplier.test_lf_applier_pandas_spacy_preprocessor_memoized _____

self = <test.labeling.apply.test_lf_applier.TestPandasApplier testMethod=test_lf_applier_pandas_spacy_preprocessor_memoized>

    def test_lf_applier_pandas_spacy_preprocessor_memoized(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_____________________ TestDaskApplier.test_lf_applier_dask _____________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask>

    def test_lf_applier_dask(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, g])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
__________________ TestDaskApplier.test_lf_applier_dask_fault __________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_fault>

    def test_lf_applier_dask_fault(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, f_bad])
        with self.assertRaises(Exception):
            applier.apply(df)
>       L = applier.apply(df, fault_tolerant=True)

test/labeling/apply/test_lf_applier.py:237: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
______________ TestDaskApplier.test_lf_applier_dask_preprocessor _______________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_preprocessor>

    def test_lf_applier_dask_preprocessor(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, fp])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
___________ TestDaskApplier.test_lf_applier_dask_spacy_preprocessor ____________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_dask_spacy_preprocessor>

    @pytest.mark.complex
    def test_lf_applier_dask_spacy_preprocessor(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:265: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______________ TestDaskApplier.test_lf_applier_pandas_parallel ________________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_parallel>

    def test_lf_applier_pandas_parallel(self) -> None:
        df = pd.DataFrame(dict(num=DATA))
        applier = PandasParallelLFApplier([f, g])
>       L = applier.apply(df, n_parallel=2)

test/labeling/apply/test_lf_applier.py:303: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:98: in apply
    return super().apply(df, scheduler=scheduler, fault_tolerant=fault_tolerant)
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
_________ TestDaskApplier.test_lf_applier_pandas_preprocessor_memoized _________

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_preprocessor_memoized>

    def test_lf_applier_pandas_preprocessor_memoized(self) -> None:
        @preprocessor(memoize=True)
        def square_memoize(x: DataPoint) -> DataPoint:
            x.num_squared = x.num**2
            return x
    
        @labeling_function(pre=[square_memoize])
        def fp_memoized(x: DataPoint) -> int:
            return 0 if x.num_squared > 42 else -1
    
        df = pd.DataFrame(dict(num=DATA))
        df = dd.from_pandas(df, npartitions=2)
        applier = DaskLFApplier([f, fp_memoized])
>       L = applier.apply(df)

test/labeling/apply/test_lf_applier.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/apply/dask.py:50: in apply
    labels = map_fn.compute(scheduler=scheduler)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:314: in compute
    (result,) = compute(self, traverse=False, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/base.py:599: in compute
    results = schedule(dsk, keys, **kwargs)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/multiprocessing.py:233: in get
    result = get_async(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:499: in get_async
    fire_tasks(chunksize)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dask/local.py:494: in fire_tasks
    fut = submit(batch_execute_tasks, each_args)
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:724: in submit
    self._adjust_process_count()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:684: in _adjust_process_count
    self._spawn_process()
../purepython/cpython-3.9/Lib/concurrent/futures/process.py:701: in _spawn_process
    p.start()
../purepython/cpython-3.9/Lib/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../purepython/cpython-3.9/Lib/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../purepython/cpython-3.9/Lib/multiprocessing/popen_spawn_posix.py:42: in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:154: in get_preparation_data
    _check_not_importing_main()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _check_not_importing_main():
        if getattr(process.current_process(), '_inheriting', False):
>           raise RuntimeError('''
            An attempt has been made to start a new process before the
            current process has finished its bootstrapping phase.
    
            This probably means that you are not using fork to start your
            child processes and you have forgotten to use the proper idiom
            in the main module:
    
                if __name__ == '__main__':
                    freeze_support()
                    ...
    
            The "freeze_support()" line can be omitted if the program
            is not going to be frozen to produce an executable.''')
E           RuntimeError: 
E                   An attempt has been made to start a new process before the
E                   current process has finished its bootstrapping phase.
E           
E                   This probably means that you are not using fork to start your
E                   child processes and you have forgotten to use the proper idiom
E                   in the main module:
E           
E                       if __name__ == '__main__':
E                           freeze_support()
E                           ...
E           
E                   The "freeze_support()" line can be omitted if the program
E                   is not going to be frozen to produce an executable.

../purepython/cpython-3.9/Lib/multiprocessing/spawn.py:134: RuntimeError
______ TestDaskApplier.test_lf_applier_pandas_spacy_preprocessor_memoized ______

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_spacy_preprocessor_memoized>

    @pytest.mark.complex
    def test_lf_applier_pandas_spacy_preprocessor_memoized(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:283: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
___________ TestNLPLabelingFunction.test_labeling_function_serialize ___________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_labeling_function_serialize>

    @pytest.mark.complex
    def test_labeling_function_serialize(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
______________ TestNLPLabelingFunction.test_nlp_labeling_function ______________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function>

    def test_nlp_labeling_function(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_________ TestNLPLabelingFunction.test_nlp_labeling_function_decorator _________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_decorator>

    def test_nlp_labeling_function_decorator(self) -> None:
        @nlp_labeling_function(pre=[combine_text])
>       def has_person_mention(x: DataPoint) -> int:

test/labeling/lf/test_nlp.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_________ TestNLPLabelingFunction.test_nlp_labeling_function_memoized __________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_memoized>

    def test_nlp_labeling_function_memoized(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
__________ TestNLPLabelingFunction.test_nlp_labeling_function_raises ___________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_raises>

    def test_nlp_labeling_function_raises(self) -> None:
    
        with self.assertRaisesRegex(ValueError, "different parameters"):
    
            @nlp_labeling_function()
>           def has_person_mention(x: DataPoint) -> int:

test/labeling/lf/test_nlp.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______ TestNLPLabelingFunction.test_nlp_labeling_function_shared_cache ________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_shared_cache>

    def test_nlp_labeling_function_shared_cache(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
________________ TestSpacyPreprocessor.test_spacy_preprocessor _________________

self = <test.labeling.preprocess.test_nlp.TestSpacyPreprocessor testMethod=test_spacy_preprocessor>

    def test_spacy_preprocessor(self) -> None:
        x = SimpleNamespace(text="Jane plays soccer.")
>       preprocessor = SpacyPreprocessor("text", "doc")

test/labeling/preprocess/test_nlp.py:10: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
______________ TestGetHashable.test_get_hashable_series_with_doc _______________

self = <test.map.test_core.TestGetHashable testMethod=test_get_hashable_series_with_doc>

    def test_get_hashable_series_with_doc(self) -> None:
>       nlp = spacy.load("en_core_web_sm")

test/map/test_core.py:400: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______________ TestNLPSlicingFunction.test_nlp_slicing_function _______________

self = <test.slicing.sf.test_nlp.TestNLPSlicingFunction testMethod=test_nlp_slicing_function>

    def test_nlp_slicing_function(self) -> None:
>       sf = NLPSlicingFunction(name="my_sf", f=has_person_mention, pre=[combine_text])

test/slicing/sf/test_nlp.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/slicing/sf/nlp.py:84: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
__________ TestNLPSlicingFunction.test_nlp_slicing_function_decorator __________

self = <test.slicing.sf.test_nlp.TestNLPSlicingFunction testMethod=test_nlp_slicing_function_decorator>

    def test_nlp_slicing_function_decorator(self) -> None:
        @nlp_slicing_function(pre=[combine_text])
>       def has_person_mention(x: DataPoint) -> int:

test/slicing/sf/test_nlp.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
snorkel/slicing/sf/nlp.py:84: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
=============================== warnings summary ===============================
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/botocore/httpsession.py:41
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/botocore/httpsession.py:41: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680
    from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext

test/classification/training/test_trainer.py::TrainerTest::test_save_load
  /home/user/snorkel/test/classification/training/test_trainer.py:250: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
    if isinstance(dict1_, collections.Mapping):

test/labeling/test_analysis.py::TestAnalysis::test_lf_conflicts
  /home/user/snorkel/snorkel/labeling/analysis.py:264: RuntimeWarning: invalid value encountered in divide
    conflicts /= self.lf_overlaps()

test/labeling/test_analysis.py::TestAnalysis::test_lf_overlaps
  /home/user/snorkel/snorkel/labeling/analysis.py:221: RuntimeWarning: invalid value encountered in divide
    overlaps /= self.lf_coverages()

test/labeling/test_convergence.py: 1 warning
test/labeling/model/test_label_model.py: 52 warnings
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/networkx/algorithms/chordal.py:206: DeprecationWarning: This will return a generator in 3.0.
    warnings.warn(msg, DeprecationWarning)

test/slicing/test_sliceaware_classifier.py::SliceCombinerTest::test_scores_pipeline
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
    _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED test/labeling/apply/test_lf_applier.py::TestPandasApplier::test_lf_applier_pandas_spacy_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestPandasApplier::test_lf_applier_pandas_spacy_preprocessor_memoized
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_fault
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_spacy_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_parallel
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_preprocessor_memoized
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_spacy_preprocessor_memoized
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_labeling_function_serialize
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_decorator
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_memoized
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_raises
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_shared_cache
FAILED test/labeling/preprocess/test_nlp.py::TestSpacyPreprocessor::test_spacy_preprocessor
FAILED test/map/test_core.py::TestGetHashable::test_get_hashable_series_with_doc
FAILED test/slicing/sf/test_nlp.py::TestNLPSlicingFunction::test_nlp_slicing_function
FAILED test/slicing/sf/test_nlp.py::TestNLPSlicingFunction::test_nlp_slicing_function_decorator
=========== 19 failed, 214 passed, 58 warnings in 286.62s (0:04:46) ============
----------------------------- Captured stderr call -----------------------------
/home/user/thefuck-master/pre_run_biend.py:3884: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6C) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3894: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(O6C) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3918: DeprecationWarning: invalid escape sequence \ 
  f.write('$extenion\ set$ & ' + ' & '.join(EXT_SET) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:3919: DeprecationWarning: invalid escape sequence \ 
  f.write('$extenion\ event$ & ' + ' & '.join(EXT_EVENT) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4046: DeprecationWarning: invalid escape sequence \_
  d_ = d.replace('_', '\_')
/home/user/thefuck-master/pre_run_biend.py:4057: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6[:10]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4067: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6[10:]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4079: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6ov[:10]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4091: DeprecationWarning: invalid escape sequence \s
  f.write('$t1 \sim_n t_2$ & ' + ' & '.join(M6ov[10:]) + '\\\\ \\hline' +'\n')
/home/user/thefuck-master/pre_run_biend.py:4213: DeprecationWarning: invalid escape sequence \_
  d_ = d.replace('_', '\_')
/home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/dash/testing/plugin.py:92: PytestDeprecationWarning: The hookimpl pytest_addhooks uses old-style configuration options (marks or attributes).
Please use the pytest.hookimpl(tryfirst=True) decorator instead
 to configure the hooks.
 See https://docs.pytest.org/en/latest/deprecations.html#configuring-hook-specs-impls-using-markers
  @pytest.mark.tryfirst
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/user/purepython/cpython-3.9/Lib/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/user/purepython/cpython-3.9/Lib/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/user/thefuck-master/pre_run_biend.py", line 102, in <module>
    from lark import Lark
ModuleNotFoundError: No module named 'lark'
______ TestDaskApplier.test_lf_applier_pandas_spacy_preprocessor_memoized ______

self = <test.labeling.apply.test_lf_applier.TestDaskApplier testMethod=test_lf_applier_pandas_spacy_preprocessor_memoized>

    @pytest.mark.complex
    def test_lf_applier_pandas_spacy_preprocessor_memoized(self) -> None:
>       spacy = SpacyPreprocessor(text_field="text", doc_field="doc")

test/labeling/apply/test_lf_applier.py:283: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
___________ TestNLPLabelingFunction.test_labeling_function_serialize ___________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_labeling_function_serialize>

    @pytest.mark.complex
    def test_labeling_function_serialize(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
______________ TestNLPLabelingFunction.test_nlp_labeling_function ______________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function>

    def test_nlp_labeling_function(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_________ TestNLPLabelingFunction.test_nlp_labeling_function_decorator _________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_decorator>

    def test_nlp_labeling_function_decorator(self) -> None:
        @nlp_labeling_function(pre=[combine_text])
>       def has_person_mention(x: DataPoint) -> int:

test/labeling/lf/test_nlp.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_________ TestNLPLabelingFunction.test_nlp_labeling_function_memoized __________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_memoized>

    def test_nlp_labeling_function_memoized(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
__________ TestNLPLabelingFunction.test_nlp_labeling_function_raises ___________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_raises>

    def test_nlp_labeling_function_raises(self) -> None:
    
        with self.assertRaisesRegex(ValueError, "different parameters"):
    
            @nlp_labeling_function()
>           def has_person_mention(x: DataPoint) -> int:

test/labeling/lf/test_nlp.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______ TestNLPLabelingFunction.test_nlp_labeling_function_shared_cache ________

self = <test_nlp.TestNLPLabelingFunction testMethod=test_nlp_labeling_function_shared_cache>

    def test_nlp_labeling_function_shared_cache(self) -> None:
>       lf = NLPLabelingFunction(name="my_lf", f=has_person_mention, pre=[combine_text])

test/labeling/lf/test_nlp.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:181: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
________________ TestSpacyPreprocessor.test_spacy_preprocessor _________________

self = <test.labeling.preprocess.test_nlp.TestSpacyPreprocessor testMethod=test_spacy_preprocessor>

    def test_spacy_preprocessor(self) -> None:
        x = SimpleNamespace(text="Jane plays soccer.")
>       preprocessor = SpacyPreprocessor("text", "doc")

test/labeling/preprocess/test_nlp.py:10: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
______________ TestGetHashable.test_get_hashable_series_with_doc _______________

self = <test.map.test_core.TestGetHashable testMethod=test_get_hashable_series_with_doc>

    def test_get_hashable_series_with_doc(self) -> None:
>       nlp = spacy.load("en_core_web_sm")

test/map/test_core.py:400: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
_______________ TestNLPSlicingFunction.test_nlp_slicing_function _______________

self = <test.slicing.sf.test_nlp.TestNLPSlicingFunction testMethod=test_nlp_slicing_function>

    def test_nlp_slicing_function(self) -> None:
>       sf = NLPSlicingFunction(name="my_sf", f=has_person_mention, pre=[combine_text])

test/slicing/sf/test_nlp.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/slicing/sf/nlp.py:84: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
__________ TestNLPSlicingFunction.test_nlp_slicing_function_decorator __________

self = <test.slicing.sf.test_nlp.TestNLPSlicingFunction testMethod=test_nlp_slicing_function_decorator>

    def test_nlp_slicing_function_decorator(self) -> None:
        @nlp_slicing_function(pre=[combine_text])
>       def has_person_mention(x: DataPoint) -> int:

test/slicing/sf/test_nlp.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:227: in __call__
    return self._lf_cls(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:91: in __init__
    self._create_or_check_preprocessor(
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/lf/nlp.py:69: in _create_or_check_preprocessor
    nlp = cls._create_preprocessor(parameters)
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/slicing/sf/nlp.py:84: in _create_preprocessor
    return SpacyPreprocessor(**parameters._asdict())
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/preprocess/nlp.py:72: in __init__
    self._nlp = spacy.load(language, disable=disable or [])
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/__init__.py:54: in load
    return util.load_model(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'en_core_web_sm'

    def load_model(
        name: Union[str, Path],
        *,
        vocab: Union["Vocab", bool] = True,
        disable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        enable: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        exclude: Union[str, Iterable[str]] = _DEFAULT_EMPTY_PIPES,
        config: Union[Dict[str, Any], Config] = SimpleFrozenDict(),
    ) -> "Language":
        """Load a model from a package or data path.
    
        name (str): Package name or model path.
        vocab (Vocab / True): Optional vocab to pass in on initialization. If True,
            a new Vocab object will be created.
        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable.
        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All others will be disabled.
        exclude (Union[str, Iterable[str]]):  Name(s) of pipeline component(s) to exclude.
        config (Dict[str, Any] / Config): Config overrides as nested dict or dict
            keyed by section values in dot notation.
        RETURNS (Language): The loaded nlp object.
        """
        kwargs = {
            "vocab": vocab,
            "disable": disable,
            "enable": enable,
            "exclude": exclude,
            "config": config,
        }
        if isinstance(name, str):  # name or string path
            if name.startswith("blank:"):  # shortcut for blank model
                return get_lang_class(name.replace("blank:", ""))()
            if is_package(name):  # installed as package
                return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]
            if Path(name).exists():  # path to model data directory
                return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]
        elif hasattr(name, "exists"):  # Path or Path-like to model data
            return load_model_from_path(name, **kwargs)  # type: ignore[arg-type]
        if name in OLD_MODEL_SHORTCUTS:
            raise IOError(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  # type: ignore[index]
>       raise IOError(Errors.E050.format(name=name))
E       OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.

../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/spacy/util.py:449: OSError
=============================== warnings summary ===============================
../purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/botocore/httpsession.py:41
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/botocore/httpsession.py:41: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680
    from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext

test/classification/training/test_trainer.py::TrainerTest::test_save_load
  /home/user/snorkel/test/classification/training/test_trainer.py:250: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
    if isinstance(dict1_, collections.Mapping):

test/labeling/test_analysis.py::TestAnalysis::test_lf_conflicts
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/analysis.py:264: RuntimeWarning: invalid value encountered in divide
    conflicts /= self.lf_overlaps()

test/labeling/test_analysis.py::TestAnalysis::test_lf_overlaps
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/snorkel/labeling/analysis.py:221: RuntimeWarning: invalid value encountered in divide
    overlaps /= self.lf_coverages()

test/labeling/test_convergence.py: 1 warning
test/labeling/model/test_label_model.py: 52 warnings
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/networkx/algorithms/chordal.py:206: DeprecationWarning: This will return a generator in 3.0.
    warnings.warn(msg, DeprecationWarning)

test/slicing/test_sliceaware_classifier.py::SliceCombinerTest::test_scores_pipeline
  /home/user/purepython/cpython-3.9/my_purepy/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
    _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED test/labeling/apply/test_lf_applier.py::TestPandasApplier::test_lf_applier_pandas_spacy_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestPandasApplier::test_lf_applier_pandas_spacy_preprocessor_memoized
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_fault
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_dask_spacy_preprocessor
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_parallel
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_preprocessor_memoized
FAILED test/labeling/apply/test_lf_applier.py::TestDaskApplier::test_lf_applier_pandas_spacy_preprocessor_memoized
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_labeling_function_serialize
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_decorator
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_memoized
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_raises
FAILED test/labeling/lf/test_nlp.py::TestNLPLabelingFunction::test_nlp_labeling_function_shared_cache
FAILED test/labeling/preprocess/test_nlp.py::TestSpacyPreprocessor::test_spacy_preprocessor
FAILED test/map/test_core.py::TestGetHashable::test_get_hashable_series_with_doc
FAILED test/slicing/sf/test_nlp.py::TestNLPSlicingFunction::test_nlp_slicing_function
FAILED test/slicing/sf/test_nlp.py::TestNLPSlicingFunction::test_nlp_slicing_function_decorator
=========== 19 failed, 214 passed, 58 warnings in 4539.21s (1:15:39) ===========
Traceback (most recent call last):
  File "/home/user/thefuck-master/pre_run_biend.py", line 102, in <module>
    from lark import Lark
ModuleNotFoundError: No module named 'lark'
